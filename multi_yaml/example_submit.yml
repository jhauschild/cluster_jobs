#!/bin/bash 

job_config:
    class: JobConfig  # JobConfig = run locally; SlurmJob = submit to slurm
    jobname: MyJob
    task: 
        type: PythonFunctionCall
        module: simulation
        function: run_simulation
        # extra_imports: 
        #     - my_other_py_module

    #script_template: slurm.sh
    requirements_slurm:
        time: '0:30:00'
        nodes: 1
    # requirements_sge:
    #     time: '0:30:00'
    #     nodes: 1

    change_parameters:
        expansion: product  # product or zip
        recursive_keys:
            - a
            - sub_params.c
        # value_lists: 
        #     - [ 128, 256, 512]
        #     - [0.5, 1.]
        #     # you can either specify all the value_lists for all parameters here, 
        #     # or have the lists distributed over the rest of the yaml file(s).
        # format_strs:
        #     - 'a_{0:04d}'
        #     - 'c_{0:.2f}'
         
        output_filename:
            # key: output_filename
            prefix: 'output'
            suffix: '.pkl'

a: [100, 500, 1000]
b: !py_eval |
    2*np.pi
# cluster_jobs.py supports an extra !py_eval tag for evaluating a python code snippet.
# Like pickle, this is a security nightmare, so don't use untrusted configs from the internet!

sub_params:
    c: !py_eval |
       np.arange(0.5, 1.5, 0.5)
    d: 2
